\documentclass[12pt]{article}
\usepackage{epsfig, epsf, graphicx, subfigure}
\usepackage{graphicx}
\usepackage{pstricks, pst-node, psfrag}
\usepackage{amssymb,amsmath}
\usepackage{verbatim,enumerate}
\usepackage{rotating, lscape}
\usepackage{multirow}
\usepackage{setspace}

\usepackage{hyperref}
\usepackage[square,sort,comma,numbers]{natbib}
%\usepackage{hyperref}

\usepackage[hang, flushmargin]{footmisc}

\setlength{\oddsidemargin}{-0.125in}
\setlength{\topmargin}{-0.5in} \setlength{\textwidth}{6.5in}
\setlength{\textheight}{9in}

\setlength{\textheight}{9in} \setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-40pt} \setlength{\oddsidemargin}{0pt}
\setlength{\evensidemargin}{0pt}
  
\setlength{\textheight}{9.4in} \setlength{\textwidth}{6.8in}
\setlength{\topmargin}{-71pt} \setlength{\oddsidemargin}{0pt}
\setlength{\evensidemargin}{-6pt} \tolerance=500
%\input psfig.tex
\setlength{\topmargin}{-56pt} \setlength{\oddsidemargin}{-6pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\wt{\widetilde}
\def\diag{\hbox{diag}}
\def\wh{\widehat}
\def\AIC{\hbox{AIC}}
\def\BIC{\hbox{BIC}}
\def\sm{\footnotesize}
%- Makes the section title start with Appendix in the appendix environment
\newcommand{\Appendix}
{%\appendix
\def\thesection{Appendix~\Alph{section}}
%\def\thesubsection{\Alph{section}.\arabic{subsection}}
\def\thesubsection{A.\arabic{subsection}}
}
\def\diag{\hbox{diag}}
\def\log{\hbox{log}}
\def\bias{\hbox{bias}}
\def\Siuu{\boldSigma_{i,uu}}
\def\ANNALS{{\it Annals of Statistics}}
\def\BIOK{{\it Biometrika}}
\def\whT{\widehat{\Theta}}
\def\STATMED{{\it Statistics in Medicine}}
\def\STATSCI{{\it Statistical Science}}
\def\JSPI{{\it Journal of Statistical Planning \&amp; Inference}}
\def\JRSSB{{\it Journal of the Royal Statistical Society, Series B}}
\def\BMCS{{\it Biometrics}}
\def\COMMS{{\it Communications in Statistics, Theory \& Methods}}
\def\JQT{{\it Journal of Quality Technology}}
\def\STIM{{\it Statistics in Medicine}}
\def\TECH{{\it Technometrics}}
\def\AJE{{\it American Journal of Epidemiology}}
\def\JASA{{\it Journal of the American Statistical Association}}
\def\CDA{{\it Computational Statistics \& Data Analysis}}
\def\JCGS{{\it Journal of Computational and Graphical Statistics}}
\def\JCB{{\it Journal of Computational Biology}}
\def\BIOINF{{\it Bioinformatics}}
\def\JAMA{{\it Journal of the American Medical Association}}
\def\JNUTR{{\it Journal of Nutrition}}
\def\JCGS{{\it Journal of Computational and Graphical Statistics}}
\def\LETTERS{{\it Letters in Probability and Statistics}}
\def\JABES{{\it Journal of Agricultural and
                      Environmental Statistics}}
\def\JASA{{\it Journal of the American Statistical Association}}
\def\ANNALS{{\it Annals of Statistics}}
\def\JSPI{{\it Journal of Statistical Planning \& Inference}}
\def\TECH{{\it Technometrics}}
\def\BIOK{{\it Bio\-me\-tri\-ka}}
\def\JRSSB{{\it Journal of the Royal Statistical Society, Series B}}
\def\BMCS{{\it Biometrics}}
\def\COMMS{{\it Communications in Statistics, Series A}}
\def\JQT{{\it Journal of Quality Technology}}
\def\SCAN{{\it Scandinavian Journal of Statistics}}
\def\AJE{{\it American Journal of Epidemiology}}
\def\STIM{{\it Statistics in Medicine}}
\def\ANNALS{{\it Annals of Statistics}}
\def\whT{\widehat{\Theta}}
\def\STATMED{{\it Statistics in Medicine}}
\def\STATSCI{{\it Statistical Science}}
\def\JSPI{{\it Journal of Statistical Planning \& Inference}}
\def\JRSSB{{\it Journal of the Royal Statistical Society, Series B}}
\def\BMCS{{\it Biometrics}}
\def\COMMS{{\it Communications in Statistics, Theory \& Methods}}
\def\JQT{{\it Journal of Quality Technology}}
\def\STIM{{\it Statistics in Medicine}}
\def\TECH{{\it Technometrics}}
\def\AJE{{\it American Journal of Epidemiology}}
\def\JASA{{\it Journal of the American Statistical Association}}
\def\CDA{{\it Computational Statistics \& Data Analysis}}
\def\dfrac#1#2{{\displaystyle{#1\over#2}}}
\def\VS{{\vskip 3mm\noindent}}
\def\boxit#1{\vbox{\hrule\hbox{\vrule\kern6pt
          \vbox{\kern6pt#1\kern6pt}\kern6pt\vrule}\hrule}}
\def\refhg{\hangindent=20pt\hangafter=1}
\def\refmark{\par\vskip 2mm\noindent\refhg}
\def\naive{\hbox{naive}}
\def\itemitem{\par\indent \hangindent2\pahttprindent \textindent}
\def\var{\hbox{var}}
\def\cov{\hbox{cov}}
\def\corr{\hbox{corr}}
\def\trace{\hbox{trace}}
\def\refhg{\hangindent=20pt\hangafter=1}
\def\refmark{\par\vskip 2mm\noindent\refhg}
\def\Normal{\hbox{Normal}}
\def\povr{\buildrel p\over\longrightarrow}
\def\ccdot{{\bullet}}
\def\bse{\begin{eqnarray*}}
\def\ese{\end{eqnarray*}}
\def\be{\begin{eqnarray}}
\def\ee{\end{eqnarray}}
\def\bq{\begin{equation}}
\def\eq{\end{equation}}
\def\bse{\begin{eqnarray*}}
\def\ese{\end{eqnarray*}}
\def\pr{\hbox{pr}}
\def\wh{\widehat}
\def\trans{^{\rm T}}
\def\myalpha{{\cal A}}
\def\th{^{th}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Marc Definitions
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand{\baselinestretch}{1.2} % Change this 1.5 or whatever
\newcommand{\qed}{\hfill\hfill\vbox{\hrule\hbox{\vrule\squarebox
   {.667em}\vrule}\hrule}\smallskip}
\newtheorem{Th}{Theorem}
\newtheorem{Proof}{Proof}
\newtheorem{Mth}{Main Theorem}
\newtheorem{Def}{Definition}
\newtheorem{Rem}{Remark}
\newtheorem{Qes}{Question}
\newtheorem{proposition}{Proposition}
\newtheorem{Lem}{Lemma}
\newtheorem{Cor}{Corollary}
\newtheorem{Exa}{Example}
\newtheorem{Eq}{Equation}
%\renewcommand{\baselinestretch}{1.5}
\def\btheta{{\boldsymbol \theta}}
\def\balpha{{\boldsymbol \alpha}}
\def\bmu{{\boldsymbol \mu}}
\def\bpi{{\boldsymbol \pi}}
\def\x{{\bf x}}
\def\a{{\bf a}}
\def\mA{\mathcal{A}}
\def\mB{\mathcal{B}}
\def\mC{\mathcal{C}}
\def\mH{\mathcal{H}}
\def\mR{\mathcal{R}}
\def\mD{\mathcal{D}}

\newtheorem{lemm}{Lemma}[section]
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}{Corollary}[thm]
\newtheorem{defi}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{example}{Example}

\def\bX{{\bf X}}
\def\bY{{\bf Y}}
\def\bZ{{\bf Z}}
\def\bU{{\bf U}}
\def\bT{{\bf T}}
\def\bV{{\bf V}}
\def\bx{{\bf x}}
\def\by{{\bf y}}
\def\bz{{\bf z}}
\def\bu{{\bf u}}
\def\bv{{\bf v}}
\def\bs{{\bf s}}
\def\ba{{\bf a}}
\def\bb{{\bf b}}
\def\bmu{{\boldsymbol \mu}}
\def\bbeta{{\boldsymbol \beta}}
\def\balpha{{\boldsymbol \alpha}}
\def\bxi{{\boldsymbol \xi}}
\def\bdelta{{\boldsymbol \delta}}
\def\blambda{{\boldsymbol \lambda}}
\def\btheta{{\boldsymbol \theta}}
\def\beeta{{\boldsymbol \eta}}
\def\bupsilon{{\boldsymbol \upsilon}}
\def\R{\mathbb R}


%\newcommand{\pr}{\mbox{Pr}}
%\newcommand{\var}{\mbox{var}}
%\newcommand{\cov}{\mbox{cov}}
%\newcommand{\logit}{\mbox{logit }}
\newcommand{\cp}{\stackrel{\mathcal{P}}{\rightarrow}}
\newcommand{\cl}{\stackrel{\mathcal{D}}{\rightarrow}}
\newcommand{\mystrut}{\vphantom{\int_0^1}}
\newcommand{\p}{\stackrel{p}{\rightarrow}}
\renewcommand{\d}{\stackrel{d}{\rightarrow}}
\newcommand{\condind}{\perp\hspace{-1em}\perp}
\newcommand{\sumi}{\ensuremath{\sum_{i=1}^{n}}}
\newcommand{\sumj}{\ensuremath{\sum_{j=1}^{n}}}
\newcommand{\eff}{\mbox{\scriptsize eff}}
\def\my{\mathcal Y}




\def\nh{\noindent\hangindent=1.5truecm\hangafter=1}
\def\cl{\centerline}
\def\ms{\medskip}
\def\ni{\noindent}
\def\ve{\vfill\eject}

\def\A{{\rm A}}
\def\ab{\allowbreak}
\def\bigmi{\,\big|\,}
\def\cI{{\cal I}}
\def\cT{{\cal T}}
\def\dt{{\dot t}}
\def\da{{\dot a}}
\def\dar{\downarrow}
\def\ddt{{\ddot t}}
\def\de{\delta}
\def\De{\Delta}
\def\ep{\epsilon}
\def\gz{g_0}
\def\ha{{\hat a}}
\def\half{^{1/2}}
\def\hg{{\hat g}}
\def\hth{{\hat\th}}
\def\hatt{{\hat t}}
\def\hom{{\widehat\om}}
\def\hOm{{\widehat\Om}}
\def\lan{\langle}
\def\ran{\rangle}
\def\lfl{\lfloor}
\def\rfl{\rfloor}
\def\mhf{^{-1/2}}
\def\mi{\,|\,}
\def\mo{^{-1}}
\def\mt{^{-2}}
\def\mth{^{-3}}
\def\mtht{^{-3/2}}
\def\om{\omega}
\def\Om{\Omega}
\def\one{^{(1)}}
\def\oqr{{\textstyle{1\over4}}}
\def\otd{{\textstyle{1\over3}}}
\def\ots{{\textstyle{1\over36}}}
\def\part{\partial}
\def\ra{\to}
\def\rai{\ra\infty}
\def\si{\sigma}
\def\Si{\Sigma}
\def\sumi{\sum_i\,}
\def\sumion{\sum_{i=1}^n\,}
\def\sumionu{\sum_{i=1}^\nu\,}
\def\sumj{\sum_j\,}
\def\sumjon{\sum_{j=1}^n\,}
\def\sumjonu{\sum_{j=1}^\nu\,}
\def\sumjonm{\sum_{j=1}^{n-1}\,}
\def\sz{^0}
\def\T{^{{\rm T}}}
\def\th{\theta}
\def\Th{\Theta}
\def\thf{{\textstyle{1\over2}}}
\def\two{^{(2)}}
\def\var{{\rm var}}
\def\z{_0}
\def\R{\mathbb{R}}
\def\bX{\mathbb{X}}
\def\y{\mathbf{y}}
\def\z{\mathbf{z}}
\def\p{\mathbf{p}}
\def\t{\mathbf{t}}
\def\A{\mbox{A}}
\def\v{\mathbf{v}}
\def\u{\mathbf{u}}
\def\s{\mathbf{s}}
\def\w{\mathbf{w}}
\def\eps{{\ensuremath\boldsymbol{\epsilon}}}
\def\sig{{\ensuremath\boldsymbol{\sigma}}}
\def\thet{{\ensuremath\boldsymbol{\theta}}}
\def\bnu{{\ensuremath\boldsymbol{\nu}}}


\def\hsp{{\hspace{.25cm}}}


\pagenumbering{arabic}

\begin{document}
\thispagestyle{empty}
\baselineskip=28pt
\vskip 5mm
\begin{center} {\Large{\bf   Simultaneous Treatment of Random and Systematic Errors in the Historical Radiosonde Temperature Archive}}
\end{center}



\baselineskip=12pt
\vskip 5mm

\begin{center}\large
Joshua M. Browning\footnote{ \baselineskip=10pt
Department of Applied Mathematics and Statistics, Colorado School of Mines, Golden, CO 80401,
USA. 303.384.2462, \\E-mail: \{jbrownin, ahering\}@mines.edu} and Amanda S. Hering$^1$




\end{center}

\baselineskip=17pt
\vskip 5mm
\centerline{\today}
\vskip 5mm

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
{\large{\bf Abstract}}
\end{center}

\baselineskip=14pt

\ni  The historical radiosonde temperature archive, and indeed any large and lengthy observational dataset, must be quality controlled before it can be used properly.   Most research on quality control for such data focuses on the identification and removal of either systematic errors (homogenization) or random errors without considering an optimal process for treatment of both.  Additionally, little has been done to evaluate  homogenization methods applied to sub-daily data, and no research exists on using robust estimators in homogenization procedures.  In this paper, we simulate realistic radiosonde temperature data and contaminate it with both systematic and random errors.  We then evaluate (1) the performance of several homogenization algorithms and (2) the sequence in which the random and systematic errors are identified and corrected.  In our simulations we find that the robust Standard Normal Homogeneity Test (SNHT) that we introduce performs better than the traditional SNHT, and it is better than several other modern alternatives.  Moreover, we find that systematic errors present in the data lead to poorer performance of random error removal algorithms, but the presence of random errors in the data is not as detrimental to homogenization algorithms.

%the effects of homogenizing data, via several homogenization algorithms, prior to or after removing errors and compare the resulting dataset with the ground truth. 

\begin{singlespacing}
\par\vfill\noindent
{\bf Some keywords:} Change Point Detection; Homogenization; Outlier Detection; Radiosonde Temperature Data

\par\medskip\noindent
{\bf Short title}:  Simultaneous Random and Systematic Error Detection

\end{singlespacing}
\clearpage\pagebreak\newpage \pagenumbering{arabic}
\begin{doublespacing}


\section{Introduction}


%: should answer "Why are you doing the study?  What's been done?  Why is what we're doing different than what's been done before?"

Any large dataset whose observations reach far back in time may require treatment for both systematic and random errors. Datasets such as the International Surface Temperature Initiative (ISTI) global land surface databank \cite{rennie14} with over 32,000 stations, and the Integrated Global Radiosonde Archive (IGRA) housed at the National Climatic Data Center (NCDC) \cite{durre06} are examples of such large datasets. Systematic errors can occur when the station location changes; the area surrounding the station becomes urbanized; or the instrumentation is changed. Random errors can occur due to faulty data transmission; sporadic instrumentation problems; keystroke entries; or errors in data management. To illustrate, Figure~\ref{fig:BasicTS} plots the temperature recorded by radiosondes at the 50 mb pressure level at Station 70219 (Bethel, Alaska, USA); this time series appears to have random and possibly systematic errors.  It is important to treat both sources of errors in  large historical datasets as robustly and automatically as possible. In most published research, methods for handling systematic and random errors are treated separately, and opinions among climate and weather scientists differ in terms of which type of error should be handled first. The purpose of this study is to shed light on the order in which systematic and random error methods should be applied to such large datasets when considering both sources of error simultaneously. In addition, robust estimators in homogenization algorithms when random errors are present have not yet been considered, so these are proposed and investigated as well.

In this paper, we  focus on the Upper Air Database (UADB) housed at the National Center for Atmospheric Research (NCAR). This archive differs from the IGRA archive in that it contains some different stations, and many of the records are older. Since the radiosonde data are the only measured values of the upper atmosphere, it is an important resource for studies in climate change \cite{elliott91, eskridge95} and for use as an input to global reanalysis datasets \cite{kalnay96, kanamitsu02}. Currently over 2,000 station locations exist, and atmospheric variables are collected at standard pressure levels as the radiosonde rises through the atmosphere. In large datasets such as these, the error detection methods must be automated since the archives are so large that visual inspections of every station are not feasible.

Many methods have been developed to homogenize radiosonde data, but most are not tested on simulated data with known contamination errors \cite{eskridge95, haimberger07, lanzante96, lanzante03, venema12}.  However, a study was recently conducted by the European Cooperation in Science and Technology to compare many different homogenization methods \cite{venema12}.  A single large, realistic dataset with known change points was simulated, and then researchers were asked to test their homogenization algorithm on the dataset.  As the researchers did not have knowledge of the true change point locations, this experiment provided a way to compare the performance of  these  methods.  

Most homogenization techniques are designed for monthly or annual time series, but radiosonde observations occur, on average, twice daily.  Some of these techniques rely on optimizing an objective function over all possible change point configurations \cite{killick12, li14, lu10, scott74}, and many of these approaches are too computationally expensive for daily data.  Additionally, some methods may only locate proposed change points and may not correct for the difference in means, which is a necessary homogenization step.  In this paper, we compare the Standard Normal Homogeneity Test (SNHT) \cite{alexandersson86}, the PELT algorithm \cite{killick12}, and binary segmentation \cite{scott74}.  We also propose a robust version of the SNHT.

Automated random error detection methods for radiosonde temperature data have not been investigated as thoroughly \cite{durre06,lanzante96}.  Models such as \cite{ignaccolo14} for  the entire vertical column using pairs of locations could be adapted for random error detection, but  recently in \cite{bell14}, several random error detection methods for a given location and pressure level are proposed and evaluated via simulated datasets.  The authors find that the optimal error detection algorithm requires two steps: first scanning for observations that are too many standard deviations from the global mean and secondly scanning for observations that are too many standard deviations from their local mean.  Robust estimators of mean and standard deviation are used in both cases to mitigate the influence of errors, and a robust, asymmetric estimate of standard deviation is introduced to account for skewness in temperature data.

However, to our knowledge, no research has been done to date describing which type of error should be handled first when a dataset contains both types of errors.  We do a simulation study in which data is contaminated with both known random errors and with known change points so that we can  evaluate the performance of our robust SNHT and the sequence in which different quality control algorithms are applied.  We henceforth refer to the choice of performing random error detection or systematic error detection first  as ``the sequence of the quality control method'' or simply ``the sequence.''  In Section 2, we discuss the details of our data simulation and contamination.  Section 3 evaluates the performance of the homogenization algorithms we use, and Section 4 gives the results from the sequencing study.  In Section 5, we present a case study of this method applied to a real dataset, and some conclusions are offered in Section 6.

\section{Simulation Method}
Observational data cannot be used to evaluate the performance of quality control (QC) and homogenization methods directly since we cannot know exactly where true change points and errors occur.  Therefore, a rigorous simulation study is developed in order to accurately compare methods and their sequence.  Evaluation of methodology via simulation is commonplace in the statistics literature, and our approach bases the simulation on actual data.  In order for this simulation study to validate methods for radiosonde data, it is crucial that we simulate data that is similar in structure to true radiosonde data.

\subsection{Modeling Radiosonde Data}
\label{ssec:model}

In order to capture seasonal and hourly trends, we fit a Generalized Additive Model (GAM) to the radiosonde temperature data.  GAMs are flexible, non-parametric models that allow the response variable to be a linear combination of smoothed functions of the input variables \cite{hastie90}.  In our case, we model temperature (for a fixed location and pressure level) as a function of hour of day, day of year, and year.  We model the annual trend with a linear term to capture long term increases or decreases in the series.  Thus, the model we fit is
\begin{equation} \label{eq:GAM}
	t_i = \beta_0 + s_1(h_i) + s_2(d_i) + \beta_1 y_i + \epsilon_i,
\end{equation}
\ni where $t_i$ is the temperature at a given station and pressure level; $h_i$, $d_i$ and $y_i$ are the hour, day, and year of the $i$-th observation, respectively; $\beta_0$ is the intercept; $\beta_1$ is the coefficient for the long term trend; and $s_1(\cdot)$ and $s_2(\cdot)$ are cubic regression splines.

Typically the error term, $\epsilon_i$, in Equation~(\ref{eq:GAM}) would be modeled as normal with some unknown variance, but the distribution of the error terms could be skewed or have heavier tails than a normal distribution.  Thus, we use a skew-$t$ distribution for the errors of this model, which has 4 parameters, $\xi, \sigma, \alpha$, and $\nu$, which are useful in controlling the first four moments of the distribution \cite{azzalini03}.  This distribution is very flexible and can handle skewed and heavy-tailed data.

Additionally, we expect there to be temporal correlation in the error terms.  However, since we have already included hourly and seasonal terms in the model, we expect most of this autocorrelation to be explained, so an AR(1) time series model is sufficient to account for the remaining structure in the residuals.  This model assumes that each error term has some fixed correlation with the error one time step in the past, and thus can be estimated by simply computing the correlation between $t_i$ and $t_{i+1}$ when the observations are equally spaced.

However, for radiosonde data, observations are not equally spaced in time.  Launches are scheduled globally at 0 and 12 UTC; however, many deviations from this pattern are observed, especially in the historic record.  Most observations are within an hour or two of the scheduled launches, but in some instances, no launches occur on a given day, and on others, more than two radiosondes are launched.   Thus, to estimate the lag-$h$  autocorrelation, ${\phi}(h)$, in hours, we must use only those observations that are $h$ time steps apart:
\begin{equation} \label{eq:ACF}
	\widehat{\phi}(h)=\frac{1}{\lvert \mathcal{P}_h\rvert} \sum_{(\widehat{\epsilon_i},\widehat{\epsilon_j}) \in \mathcal{P}_h} \frac{(\widehat{\epsilon_i}-\bar{\epsilon_i})(\widehat{\epsilon_j}-\bar{\epsilon_j})}{\sqrt{s_{\epsilon_i} s_{\epsilon_j}}},
\end{equation}
\ni where $\mathcal{P}_h$ is the set of all pairs of residuals that are $h$ hours apart (or within some window), and $\widehat{\epsilon_i}$ is the observed residual from Equation~(\ref{eq:GAM}).  For an AR(1) model, we need only estimate $\phi(\cdot)$ at $h=12$ hours, and we use a window of 5\% of 12 hours, or 0.6 hours.

\subsection{Data Simulation}
\label{ssec:sim}

The data simulation procedure has seven steps:
\begin{enumerate}
	\item Fit Equation~(\ref{eq:GAM}) to radiosonde temperature data at a given location and pressure level.  Then, fit a skew-$t$ distribution to the error terms, and model the autocorrelation with Equation~(\ref{eq:ACF}).
	\item We choose a fixed time period and assume that two observations occur for each day within that time period: one in the morning and one in the evening.  The time of each morning (evening) observation is simulated by sampling a time from the morning (evening) subset of the observed data.  This process is done to ensure that variability in the simulated hour of observation is comparable with that of the observed data.
	\item We use the GAM model fit in step 1 to determine the expected value of temperature at the simulated time, denoted $\hat t_i$.
	\item To simulate the noise in the observations, we randomly draw values $\delta_i$ from a skew-t distribution with parameters as fit in step 1.
	\item We wish to introduce autocorrelation in these $\delta_i$.  Thus, we simulate an AR(1) model via
	\begin{equation*}
	\epsilon_i = \widehat{\phi}(12)^{\Delta_{i-1}/12} \epsilon_{i-1} + \delta_i,
	\end{equation*}
	where $\epsilon_i$ is the simulated noise in the model at time $i$, and $\Delta_{i-1}$ is the time difference, in hours, between the $(i-1)$th and $i$th observation.  Note that the $k$th term in this series will depend on all the previous $k-1$ values.  To ensure the correct correlation structure, we simulate 1,000 more values than we need and discard the first 1,000.
	\item Then, $\hat{t}_i$ is added to $\epsilon_i$ to construct a simulated series that is similar to real radiosonde temperatures.
	
	\item Lastly, we contaminate this data with systematic and random errors.  (a) Random errors are generated by sampling 1, 2, 5 or 10\% of the observations and adding or subtracting a random error following a distribution of $N(10\sigma,1\sigma^2)$, where $\sigma$ is the standard deviation of the simulated series, estimated from Equation (\ref{eq:GAM}).  (b) Systematic errors are generated by sampling 1, 2, or 3 observations uniformly per simulated decade and then drawing a break size from a $N(0,0.04 \sigma^2)$.  The break size is then added to all observations after the change point.  Both the contaminated and uncontaminated datasets are stored for comparison.  Figure~\ref{fig:simExample} shows an example of one of the radiosonde temperature datasets as well as three different realizations of simulated and contaminated datasets.
\end{enumerate}

We vary several additional factors within our data simulation to understand the effect that each factor has on homogenization algorithms and the sequence in which the algorithms are applied.

\textbf{Climate Zones:} Radiosonde temperature data from different climate zones can be dramatically different, and so we analyze data from many different climate zones.  In \cite{bell14}, ten representative stations are chosen and analyzed from ten different climate types, and we simulate data based on models fit to these ten stations.

\textbf{Pressure Level:} Radiosonde temperature data can also vary  over pressure level, and so we analyze the pressure levels chosen in \cite{bell14}: 100 mb, 300 mb, and 850 mb.

\textbf{Sample Size:}  For the sequencing study, sample sizes of twice-daily data simulated for 20, 40, and 80 years are used.  The study comparing homogenization algorithms, however, is much more computationally expensive, so we use sample sizes of 10, 20, and 40 years.

\section{Homogenization Algorithms}

Radiosonde observations are collected over long periods of time, as long as 100 years for some stations, and therefore systematic changes in the mean temperature are not uncommon.  These errors can happen for one of many reasons: changes in instrumentation, relocation of a station, post-processing of data, etc.  Methods which detect and/or correct these errors are referred to as homogenization algorithms, and many such techniques have been developed by the meteorological community \cite{alexandersson86, domonkos13, gruber08, haimberger07, lanzante03, li14, lu10, venema12}.  Many of the homogenization algorithms make use of metadata, which document changes in the data collection process and/or compare data from neighboring stations.  We do not evaluate such algorithms since we simulate data from one station and pressure level at a time.  In \cite{haimberger07}, SNHT is applied by combining both metadata and the ERA-40, but we use a simplified version that operates purely on the observed data.

In this section, we compare the abilities of four different homogenization algorithms to detect systematic errors when random errors are also present in the data.  We summarize the methods we investigate, namely Binary Segmentation (BinSeg) \cite{scott74}, Pruned Exact Linear Time (PELT) \cite{killick12}, SNHT, and a new robust SNHT.  We simulate data as described in Section 2 and then introduce change points and random errors, and we evaluate the ability of the algorithms to detect the known change points. 

\subsection{Methodology}
\label{ssec:methodology}

Two algorithms, BinSeg and PELT, detect the number and location of change points by optimizing a cost function of the form
\begin{equation}
	\sum_{i=1}^{m+1} [\mathcal{C}(y_{(\tau_{i-1}+1):\tau_i})] + \beta f(m),
	\label{eq:cost}
\end{equation}
where $\tau_i$ is the $i$th change point; $m$ is the number of change points; $\mathcal{C}$ is a cost function; $y_{(\tau_{i-1}+1):\tau_i}$ is the observed data between the $(i-1)$ and $i$th change point; and $\beta f(m)$ is a penalty term on the number of change points to prevent overfitting \cite{killick12}.  Note that, for notational convenience, $\tau_{m+1}$ is defined to be the last observation.  Often, $\mathcal{C}$ is chosen to be twice the negative log likelihood, and $f(\cdot)$ is linear.

Optimization of Equation (\ref{eq:cost}) can be done in several ways.  BinSeg uses a divide-and-conquer algorithm: each observation is considered a candidate change point, and the one which leads to the largest reduction in the cost function is chosen as a change point.  This change point then segments the data into two groups, and the same procedure is repeated on each segment.  If no observations lead to a reduction in the cost function, then the procedure is terminated.  BinSeg is known to be computationally efficient but is not guaranteed to reach the global minimum of the cost function.

PELT is another algorithm for optimizing Equation (\ref{eq:cost}), but it computes the exact minimum.  It proceeds recursively as follows: first, the optimal number and location of change points is determined for observations 1 and 2 only.  The optimal number and location of change points for the first three observations is then determined using this information, and more generally the optimal number and location of change points for the first $k+1$ observations is determined by considering the optimal configurations for the first $2, 3, \ldots, k$ observations.  PELT is computationally efficient.  For our analysis, we used the BinSeg and PELT algorithms implemented in the \texttt{changepoint} package in R \cite{killick14}.

The SNHT test works as follows.  For each observation, two means are computed: one for the $N$ days prior to observation $i$, $\bar{X}_{L,i}$, and one for the $N$ days following, $\bar{X}_{R,i}$.  Then, the test statistic
\begin{equation}
	T_i = \frac{N}{s_i}\left( (\bar{X}_{L,i}-\bar{X}_i)^2 + (\bar{X}_{R,i}-\bar{X}_i)^2\right),
	\label{eq:Hom}
\end{equation}

\textbf{[Correct equation, discuss Haimberger reference (and paper he references)]}

\ni is computed where $\bar{X}_i$ is the mean of $\bar{X}_{L,i}$ and $\bar{X}_{R,i}$, and $s_i$ is the estimated standard deviation over the $N$ days prior and $N$ days following observation $i$.  If there are not $N$ observations both before and after the current observation, no test is performed.  If the largest $T_i$ exceeds some threshold at time $i=i^*$, we conclude that a change point occurred at time $i^*$, and we adjust all observations after time $i^*$ by $\bar{X}_{L,i^*}-\bar{X}_{R,i^*}$.  Homogenization now proceeds iteratively.  $T_i$ is recomputed for all $i$ that are sufficiently far away from the current change points, $i\in\{1,\ldots,n\} \setminus \{i^*-k, \ldots, i^*+k\}$, and the test is performed again until no $T_i$ exceed the threshold, and we use $k=N$.  In \cite{haimberger07}, a threshold of 100 is recommended, and we find this value to work well in our simulations.  Note that in practice, it is generally preferable to homogenize to the most recent data, as that data is considered to be more reliable, and some follow this convention \cite{domonkos13}. %Section 2.3

We propose an alternative estimator that replaces the means and standard deviation in Equation~(\ref{eq:Hom}) with the Huber M-estimator of the mean and standard deviation \cite{huber11}.  These robust estimators of center and spread are computed as follows:
\begin{enumerate}
	\item First, the estimates of the mean, $\hat{\mu}$, and standard deviation, $\hat{\sigma}$, are initialized to
	\begin{align*}
		\hat{\mu} &= \mbox{median}(\mathbf{x})\\
		\hat{\sigma} &= \mbox{MAD}(\mathbf{x}),
	\end{align*}
	where $\mathbf{x}$ is a vector of the data, and $MAD$ is the median absolute deviation, defined as
	\begin{equation*}
		MAD = \mbox{median}( \lvert x_i - \mbox{median}(\mathbf{x}) \rvert ).
	\end{equation*}
	\item Then, Winsorized values, $y_i$, are computed.  These are defined as
	\begin{equation*}
		y_i = \left\{ \begin{array}{ll}
			\hat{\mu}-k \hat{\sigma} & : x_i \leq \hat{\mu}-k \hat{\sigma}\\
			x_i & : \hat{\mu}-k \hat{\sigma} < x_i \leq \hat{\mu}+k \hat{\sigma}\\
			\hat{\mu}+k \hat{\sigma} & : x_i > \hat{\mu}+k \hat{\sigma},\\
		\end{array} \right.
	\end{equation*}
	and $k$ is commonly taken to be 1.5, which is what we use.
	\item Updated estimates of $\hat{\mu}$ and $\hat{\sigma}$ are computed as the mean of $\mathbf{y}$ and the standard deviation of $\mathbf{y}$, respectively.
	\item Steps 2 and 3 are repeated until $\hat{\mu}$ changes by less than $10^{-6} \hat{\sigma}$.
\end{enumerate}

\ni This definition forces unusually large observations to have little to no influence on the estimators of the mean and standard deviation, and they are robust against random errors, which may be present during homogenization.  BinSeg and PELT are not robust against random errors when $\mathcal{C}$ is chosen to be twice the negative Gaussian log likelihood.  An \texttt{R} package implementing this method is available at \url{http://inside.mines.edu/~jbrownin/snht_1.0.tar.gz}.

\textbf{[Add paragraph about removing seasonal trends here.]}

%http://inside.mines.edu/$\sim$jbrownin/snht\_1.0.tar.gz.

Evaluation of homogenization algorithms can be done by computing the number of simulated change points in the data that were accurately detected.  However, it is unlikely that a homogenization algorithm will detect the exact time of the change point, and thus hit rate is not a very useful metric.  Instead, we use efficiency as defined in \cite{domonkos13}.  Let $\mathbf{x}$, $\mathbf{c}$, and $\mathbf{h}$ be the original, contaminated, and contaminated and homogenized time series, respectively and let the $i$-th observation be denoted by $x_i, c_i$, and $h_i$ respectively.  The Root Mean Square Error (RMSE) of $\mathbf{h}$ is then defined as follows:
\begin{equation*}
	\mbox{RMSE}(\mathbf{h}) = \sqrt{\frac{1}{n} \sum_{i=1}^n (h_i-x_i)^2}.
\end{equation*}
Then, the efficiency of the homogenized series, where 1 means perfect skill, 0 means no improvement, and negative values indicate degradation is
\begin{equation*}
	\mbox{Eff}(\mathbf{h}) = \frac{\mbox{RMSE}(\mathbf{c})-\mbox{RMSE}(\mathbf{h})}{\mbox{RMSE}(\mathbf{c})}.
\end{equation*}
The homogenization algorithm is not designed to locate or correct random errors.  Furthermore, random errors in the data introduce variability in the estimate of efficiency, so we remove the random errors in $\mathbf{c}$ and $\mathbf{h}$ before computing the RMSE scores.  

We compare the efficiency of all four different homogenization algorithms on simulated datasets.  The simulated datasets are randomly selected to be either  10, 20, or 40 years long, and change point locations are simulated uniformly at random across the entire time series excluding the first and last year.  We simulate either one, two, or three change points per decade.  All of the homogenization algorithms considered have tuning parameters: for PELT and BinSeg we must choose penalty functions and the $\beta$ constant, and for SNHT and its robust variant we must specify the period $N$.  Thus, in our simulations we vary the following tuning parameters to observe their effect on the overall performance:

\begin{itemize}
	\item PELT: We consider penalties of $\beta=n/2$, $n$, $2n$, $4n$, and  $8n$.
	\item BinSeg: We use no penalty term and instead restrict the maximum number of change points that can occur, varying from 1 to 10.
	\item SNHT: This algorithm computes means of seasonal data, so periods which are multiples of a year should be considered.  Thus, we use one and two year averaging windows with $N=365$ or $N=730$.
	\item Robust SNHT: We  use $N=365$ and $N= 730$.
\end{itemize}





In summary, the simulation process is as follows:

\begin{enumerate}
	\item Simulate and contaminate data as described in Section~\ref{ssec:sim}.
	\item Apply each homogenization algorithm to the contaminated dataset.
	\item Store the efficiency of each of the homogenization algorithms.
	\item Steps 1-3 are repeated 1,000 times for each climate zone and pressure level.
\end{enumerate}

\subsection{Results}

\label{sec:HomResults}


Figure~\ref{fig:homEfficiency} depicts a boxplot of the efficiencies measured for each of the different algorithms across all 30,000 simulations (1,000 simulations for each of 3 pressure levels and each of 10 stations).  \textbf{[Correct simulation numbers/methodology here.]}  The robust version of the SNHT appears to achieve the best efficiency among all homogenization algorithms considered.  The BinSeg algorithms perform best when we force the algorithm to choose a small number of change points.  However, in practice, we will not know the true number of change points, and the BinSeg algorithm is very sensitive to this choice.  The PELT algorithm appears to perform best with a penalty of $n$, but its performance is  worse than the alternative algorithms.

To further understand the performance of these algorithms, and to understand their sensitivity to different simulation parameters, we fit a logistic regression model to the simulation results.  The response variable is 1 if efficiency is positive and 0 otherwise, and the independent variables we use are the sample size $n$, the outlier contamination rate, the station, the pressure level, and the homogenization algorithm.  We fit 5 different logistic regression models: first one with main effects and then models with $k$-way interactions, where $k=2,3,4,5$.  Table~\ref{tab:homOrdDev} reports the deviance for each model.  As the deviance does not decrease substantially after $k$ increases beyond 2, we use the model with only 2-way interaction terms.

Table~\ref{tab:homOrd} displays the average fitted probability as a function of $n$, outlier contamination, and the homogenization method.  \textbf{[and if the seasonal trend has been removed]}  The first number indicates the fitted efficiency, averaged across all station and pressure level combinations, and the number in parentheses indicates the proportion of station and pressure level combinations where this model attains the highest fitted efficiency.  The robust SNHT is the superior model in almost all scenarios.  However, the traditional SNHT is occasionally better when the outlier contamination rate is small (0\% or 1\%).  Also, a longer period for the robust SNHT should be used when more data is available, as the robust-365 tends to perform best for the 10 and 20 year data but the robust-730 performs best for the 40 year data.  Therefore, we use the robust SNHT for the remainder of this paper with $N=365$.

Plots of the fitted probability that efficiency is positive are given in Figure~\ref{fig:homFitEff}.  The center of each error bar is the mean of the fitted probability over all stations and pressure levels, and the max (min) of the error bar is the highest (lowest) fitted efficiency over all station and pressure level combinations.  As seen previously, this plot shows that the SNHT and robust SNHT attain the highest fitted probabilities in almost all cases.  Interestingly, the efficiency seems to improve as the outlier contamination rate increases, at least for $N=40$.

\section{Sequencing Study}

Many radiosonde temperature datasets have observations collected over long periods of time.  Thus, it is possible and likely that both systematic and random errors exist in the data.  It is not clear if random errors should be removed from the data prior to systematic errors, or vice versa.  Thus, this simulation study investigates the performance of different sequences of these quality control methods.

\subsection{Random Error Detection}
\label{sec:ranErr}
We follow the random error identification process developed and tested in \cite{bell14}.  Given that errors are present in the data, traditional methods of computing the mean and standard deviation are known to perform poorly.  Thus, the authors use the two-sided Huber estimator, which produces a robust measure of the location and measures of scale for both the left and right sides of the distribution \cite{huber11}.  The two-sided Huber estimator differs from the estimator described in Section~\ref{ssec:methodology} only in that it produces two estimates of scale, $\sigma_R$ and $\sigma_L$.  The estimate for $\sigma_R$ ($\sigma_L$) is computed using only the data to the right (left) of $\hat{\mu}$.

Anderson et al.~\cite{bell14} investigate several different strategies for selecting subsets of observations with which to estimate the Huber mean and standard deviations.  The \emph{Global} set uses all of the observations to estimate the parameters, and the \emph{Hourly Combined} set takes all observations within  a 45 day and 12 hour window of each observation across all years and computes parameter estimates for each one.  Their final algorithm first removes observations whose $z$-scores based on the Global parameter estimates are greater than 6, and then removes observations whose $z$-scores  based on the Hourly Combined parameter estimates exceed 5.  

%detection methods that estimate the Huber mean and standard deviations on different subsets of the data.  These subsets are defined by moving daily windows and hourly groupings, as well as considering a global approach which uses all observations.  We examine each method and agree with the authors that the best method was the  ``Hourly Combined.''  This approach searches for errors using the entire dataset first and then computes the estimators on subsets defined by hourly groupings and daily windows.

\subsection{Sequencing Simulation}

We apply four different sequencings of homogenization and random error identification to the data: homogenization followed by error detection; error detection followed by homogenization; homogenization followed by error detection followed by homogenization; and error detection followed by homogenization followed by error detection.  We refer to these approaches as ``Sys-Ran,'' ``Ran-Sys,'' ``Sys-Ran-Sys,'' and ``Ran-Sys-Ran,'' respectively.

We hypothesize that many random errors will not be detected if the data is not homogenized and that the homogenization procedure will not perform as well if random errors are not first removed.  For these reasons, we included the two additional methods ``Sys-Ran-Sys'' and ``Ran-Sys-Ran''.  In both of these approaches, a homogenization procedure is performed after random error detection.  Likewise, a random error detection will be performed after a homogenization algorithm as well.

In summary, the simulation process is as follows:

\begin{enumerate}
	\item Simulate and contaminate data as described in Section~\ref{ssec:sim}.
	\item Apply each sequencing of the quality control process.
	\item Store the true and false positive rate for random error detection as well as the efficiency of the homogenization algorithm.  The true positive rate, TPR, is defined as the percent of identified errors that are random errors, and the false positive rate, FPR, is defined as the percent of identified errors that are not random errors.
	\item Steps 1-3 are repeated 1,000 times for each climate zone and pressure level.
\end{enumerate}

\subsection{Sequencing Results}

The percent of error contamination as well as the number of simulated change points in the data can strongly influence TPR and FPR.  Thus, we again fit logistic regression models to the simulation results, where we model each of TPR, FPR, and the probability that efficiency is positive as the response variables.  The dependent variables are sample size, outlier contamination rate, station, pressure level, and sequencing.

We begin by fitting five logistic models for each of the three responses, first with only main effects and then models with all $k$-way interaction terms, where $k=2,3,4,5$.  The deviances are given in Table~\ref{tab:devSeq}.  We again find that the deviance does not decrease much when 3-way interaction terms are included in the model, and thus we use models with 2-way interaction terms for all three responses.

For the TPR model, we find that there is no significant difference between the sequencings ``Ran-Sys-Ran,'' ``Sys-Ran,'' and ``Sys-Ran-Sys.''  Table~\ref{tab:fitTPR} shows the fitted TPR averaged across all stations and pressure levels, and the number in parentheses shows the percent of the time when that model attains the highest fitted TPR.  Additionally, these effects are plotted in Figure~\ref{fig:fitTPR}.  The table shows that the ``Ran-Sys'' sequencing performs best when the outlier contamination rate is small and when the sample size is relatively small.  The other sequences perform quite similarly.  

For the FPR model, we found no significant difference between the sequencings ``Sys-Ran'' and ``Sys-Ran-Sys''.  Table~\ref{tab:fitFPR} shows the fitted false positive rates averaged across all stations and pressure levels.  Additionally, these effects are plotted in Figure~\ref{fig:fitFPR}.  In almost all simulations, ``Ran-Sys'' attained the lowest FPR; however, FPR is quite low across all models.  Due to this fact, and the conclusions from the TPR model, we recommend one of the sequencings ``Ran-Sys-Ran'', ``Sys-Ran'', or ``Sys-Ran-Sys'' if the end goal is to maximize FPR and minimize TPR.

Lastly, results from fitting the efficiency model are shown in Table~\ref{tab:fitEff}.  The largest fitted efficiency is almost always obtained with the sequence ``Sys-Ran-Sys''.  However, as shown in Figure~\ref{fig:fitEffOrd}, the difference among the four sequencings is not statistically significant.  Thus, we conclude that the sequencing chosen does not appear to have a large effect on the efficiency of the final homogenized data.

%For TPR, we find significant two-way interaction terms: the sequencing with both the simulated number of breaks and the percent of error contamination.  Figure~\ref{fig:FPR} shows interaction plots, and it is clear that, for example, the influence of outlier contamination changes as the sequencing changes.  However, the interaction effects are small and, while statistically significant, are not very meaningful in interpretation.  However, it is evident that the ``Ran-Sys'' approach performs poorly compared to the three alternatives.  This suggests that it is important to homogenize the data prior to performing error detection procedures.

%Using the efficiency metric defined in Section~\ref{sec:HomResults} as the response,  we use a 3-way ANOVA to assess the influence of percent of error contamination, the number of simulated change points, and the sequencing.  We find that the only significant interaction term is between the percent error contamination and the number of simulated change points.  \textbf{[And how does the interaction behave?  Describe what you see in the figure.]} Furthermore, the influence of the sequencing is not significant (see Figure~\ref{fig:Efficiency}). \textbf{[Sequencing is not significant at all??  Not even as a main effect? It does appear to affect TPR, so we need to figure out what this means in the context of the problem.  Does sequencing have no effect at all?]}

\section{Case Study}

In \cite{haimberger07}, station 70219 (Bethel, Alaska, USA) is analyzed for change points.  We perform a similar analysis, although we use raw radiosonde temperatures rather than the difference between the observed temperature  and a reanalysis.  We apply the robust SNHT to this time series followed by the outlier detection algorithm described in Section~\ref{sec:ranErr}.  As the dataset contains 53 years of data, we use a window of 2 years.

The algorithm detected a total of 15 change points and 19 outliers.  The detected change points have mean shifts ranging from 1.01$^\circ$C to 2.80$^\circ$C, and the average is 1.55$^\circ$C.  The global random error detection algorithm identified 12 errors, with test statistics ranging from 6.91 to 28.51 and averaging 15.57.  The windowed random error detection algorithm detected an additional 7 errors, with test statistics ranging from 5.63 to 6.95 and averaging 6.12. Figure~\ref{fig:caseStudy} depicts a plot of the time series before and after the quality control algorithm has been applied.  Only a subset of the data is plotted in the middle panel in order to show the effects of homogenization more clearly.  In the 10 year period shown, three change points are detected as indicated by the dashed vertical lines.  The detected change points shift the mean of the process, and the corrections made in the quality controlled dataset seem to improve the homogeneity of the final product.

\section{Conclusion}

In this study we evaluate several different homogenization techniques, and we find that the robust SNHT method performs well.  It attains a high efficiency, indicating that this method is reasonably effective at returning the data to its uncontaminated state.  It attains higher efficiencies then the BinSeg and PELT algorithms, and it outperforms the non-robust SNHT when the outlier contamination rate is larger than 1\%.  The optimal period appears to be a function of the size of the dataset and should increase as more data is available.

We also evaluate the effect that the sequence in which the random error detection and homogenization algorithms are applied have on the final performance of the overall quality control routine.  We find that failing to remove systematic errors before searching for random errors leads to a much lower true positive rate of the error removal algorithm in most cases.  However,  the removal of random errors first does not have a large influence on the detection of systematic errors.

In the absence of metadata regarding a station's history, we recommend performing data homogenization first followed by random error detection.  This two step procedure performs significantly better than its reversal, and it performs similarly to three step procedures.  The three step procedures do not perform significantly better than ``Sys-Ran.''  Since the three step procedures are more computationally expensive, especially given the size of the radiosonde archive, we recommend against their use.  Our recommended approach can be applied throughout the archive with minimal human intervention;   however, gains in random and systematic error detection may be realized if metadata, multiple pressure levels, or multiple station locations are combined, as in \cite{ignaccolo14}.  More work is needed to determine how to best handle both types of errors  when such additional information is incorporated.   

\subsection*{Acknowledgments} The authors wish to thank the organizers and participants of the SAMSI Surface Temperature Initiative Workshop held at the National Center for Atmospheric Research in Boulder, Colorado on July 8-16, 2014 for helpful discussions regarding the content of this paper.

\end{doublespacing}


\bibliographystyle{myabbrvnat}

\bibliography{mybib}

\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%TABLES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[ht]
	\centering
	\begin{tabular}{lcc}
  		\hline
		Model Type & Deviance & \% Reduction\\
		\hline
		Intercept Only & 672836 & ---\\ 
  		Main Effects & 529612 & 21.29\%\\ 
  		2-Way Interactions & 501158 & 5.37\%\\ 
  		3-Way Interactions & 490553 & 2.12\% \\ 
  		4-Way Interactions & 487125 & 0.70\% \\ 
  		5-Way Interactions & 486493 & 0.13\% \\ 
   		\hline
	\end{tabular}
	\caption{Deviance for the efficiency logistic regression models.}
	\label{tab:homOrdDev}
\end{table}

\begin{landscape}
\begin{table}[ht]
\centering
\begin{tabular}{cc|llllll}
  \hline
Number & Outlier & & & & & &\\ 
of Years & Contamination & BinSeg-3-log(n) & PELT-n/2 & SNHT-365 & SNHT-730 & robust-365 & robust-730 \\ 
  \hline
 & 0\% &  46.8\% (0\%) & 39.5\% (0\%) & 96.9\% (20\%) & 96.7\% (3\%) & \textbf{97.3\% (70\%)} & 97.0\% (7\%) \\ 
   & 1\% &  49.4\% (0\%) & 41.4\% (0\%) & 96.8\% (3\%) & 96.7\% (0\%) & \textbf{97.6\% (87\%)} & 97.1\% (10\%) \\ 
  10 & 2\% &  52.0\% (0\%) & 43.4\% (0\%) & 96.7\% (0\%) & 96.6\% (0\%) & \textbf{97.9\% (97\%)} & 97.3\% (3\%) \\ 
   & 5\% &  59.8\% (0\%) & 49.4\% (0\%) & 96.4\% (0\%) & 96.5\% (0\%) & \textbf{98.6\% (100\%)} & 97.8\% (0\%) \\ 
   & 10\% &  71.9\% (0\%) & 59.2\% (0\%) & 95.6\% (0\%) & 96.3\% (0\%) & \textbf{99.3\% (100\%)} & 98.3\% (0\%) \\ 
  \hline
   & 0\% &  65.3\% (0\%) & 50.3\% (0\%) & 96.2\% (0\%) & 96.6\% (23\%) & 96.5\% (23\%) & \textbf{96.8\% (53\%)} \\ 
   & 1\% &  68.2\% (0\%) & 52.7\% (0\%) & 96.1\% (0\%) & 96.6\% (0\%) & \textbf{97.0\% (50\%)} & \textbf{97.0\% (50\%)} \\ 
  20 & 2\% &  71.0\% (0\%) & 55.2\% (0\%) & 96.1\% (0\%) & 96.6\% (0\%) & \textbf{97.5\% (80\%)} & 97.3\% (20\%) \\ 
   & 5\% &  78.4\% (0\%) & 62.4\% (0\%) & 95.9\% (0\%) & 96.7\% (0\%) & \textbf{98.4\% (100\%)} & 97.8\% (0\%) \\ 
   & 10\% &  87.7\% (0\%) & 73.1\% (0\%) & 95.6\% (0\%) & 96.9\% (0\%) & \textbf{99.3\% (100\%)} & 98.6\% (0\%) \\ 
  \hline
   & 0\% &  90.1\% (10\%) & 72.4\% (0\%) & 93.9\% (0\%) & 96.2\% (43\%) & 94.2\% (0\%) & \textbf{96.2\% (47\%)} \\ 
   & 1\% &  91.6\% (10\%) & 75.2\% (0\%) & 94.1\% (0\%) & 96.4\% (17\%) & 95.2\% (0\%) & \textbf{96.6\% (73\%)} \\ 
  40 & 2\% &  92.9\% (10\%) & 77.8\% (3\%) & 94.3\% (0\%) & 96.6\% (0\%) & 96.0\% (0\%) & \textbf{97.0\% (87\%)} \\ 
   & 5\% &  95.8\% (10\%) & 84.5\% (7\%) & 94.7\% (0\%) & 97.1\% (0\%) & 97.8\% (27\%) & \textbf{98.0\% (57\%)} \\ 
   & 10\% &  98.3\% (10\%) & 91.9\% (3\%) & 95.4\% (0\%) & 97.7\% (0\%) & \textbf{99.2\% (87\%)} & 98.9\% (0\%) \\ 
\hline
\end{tabular}
\caption{Fitted efficiency averaged over all station and pressure level combinations.  Numbers in parentheses indicate the percent of station and pressure level combinations where the given model obtained the highest fitted efficiency. Bolded numbers are the highest within each row.}
\label{tab:homOrd}
\end{table}
\end{landscape}

\begin{table}[ht]
\centering
\begin{tabular}{l|cc|cc|cc}
  \hline
	& \multicolumn{2}{c|}{\textbf{TPR}} & \multicolumn{2}{c|}{\textbf{FPR}} & \multicolumn{2}{c}{\textbf{Efficiency}}\\
	Model Type & Deviance & \% Reduction & Deviance & \% Reduction & Deviance & \% Reduction\\
  \hline
	Intercept Only & 6240630 & --- & 5835529 & --- & 159942 & ---\\
	Main Effects  & 4631181 & 25.79\% & 1244423 & 78.68\% & 136467 & 14.68\%\\
	2-Way Interactions  & 4101383 & 11.44\% & 279232 & 77.56\% & 132980 & 2.56\%\\
	3-Way Interactions  & 4058965 & 1.03\% & 258216 & 7.53\% & 132585 & 0.30\%\\
	4-Way Interactions  & 4049724 & 0.23\% & 255145 & 1.19\% & 132421 & 0.12\%\\
	5-Way Interactions  & 4047592 & 0.05\% & 254845 & 0.12\% & 132411 & 0.01\%\\
   \hline
\end{tabular}
\caption{Deviance for the sequencing logistic regression models.}
\label{tab:devSeq}
\end{table}

\begin{landscape}
\begin{table}[ht]
	\centering
	\begin{tabular}{cc|llll}
  		\hline
		Number & Outlier & & & &\\ 
		of Years & Contamination & Ran-Sys & Ran-Sys-Ran & Sys-Ran & Sys-Ran-Sys\\ 
 		\hline
		 & 0\% & \textbf{56.9\% (100\%)} & 48.4\% (0\%) & 48.4\% (0\%) & 48.4\% (0\%) \\ 
		 & 1\% & \textbf{55.2\% (100\%)} & 48.6\% (0\%) & 48.6\% (0\%) & 48.6\% (0\%) \\ 
		20 & 2\% & \textbf{53.4\% (100\%)} & 48.8\% (0\%) & 48.8\% (0\%) & 48.8\% (0\%) \\ 
		 & 5\% & 48.0\% (0\%) & \textbf{49.4\% (63\%)} & 49.4\% (0\%) & 49.4\% (37\%) \\ 
		 & 10\% & 39.2\% (0\%) & 50.4\% (63\%) & 50.4\% (0\%) & \textbf{50.4\% (37\%)} \\ 
		\hline
		 & 0\% & \textbf{53.8\% (100\%)} & 49.2\% (0\%) & 49.2\% (0\%) & 49.2\% (0\%) \\ 
		 & 1\% & \textbf{51.9\% (100\%)} & 49.3\% (0\%) & 49.3\% (0\%) & 49.3\% (0\%) \\ 
		40 & 2\% & \textbf{50.0\% (83\%)} & 49.4\% (3\%) & 49.4\% (0\%) & 49.4\% (13\%) \\ 
		 & 5\% & 44.3\% (0\%) & \textbf{49.6\% (63\%)} & 49.6\% (0\%) & 49.6\% (37\%) \\ 
		 & 10\% & 35.2\% (0\%) & 50.0\% (60\%) & 50.0\% (0\%) & \textbf{50.0\% (40\%)} \\ 
		\hline
		 & 0\% & 47.5\% (0\%) & 50.8\% (63\%) & 50.8\% (0\%) & \textbf{50.8\% (37\%)} \\ 
		 & 1\% & 45.4\% (0\%) & 50.7\% (63\%) & 50.7\% (0\%) & \textbf{50.7\% (37\%)} \\ 
		80 & 2\% & 43.3\% (0\%) & 50.6\% (63\%) & 50.6\% (0\%) & \textbf{50.6\% (37\%)} \\ 
		 & 5\% & 37.1\% (0\%) & 50.1\% (60\%) & 50.1\% (0\%) & \textbf{50.1\% (40\%)} \\ 
		 & 10\% & 27.8\% (0\%) & 49.4\% (40\%) & 49.4\% (0\%) & \textbf{49.4\% (60\%)} \\ 
		\hline
	\end{tabular}
	\caption{Fitted TPR averaged over all station and pressure level combinations.  Numbers in parentheses indicate the percent of station and pressure level combinations where the given sequencing obtained the highest fitted TPR. Bolded numbers are the highest within each row.}
	\label{tab:fitTPR}
\end{table}
\end{landscape}

\begin{landscape}
\begin{table}[ht]
	\centering
	\begin{tabular}{cc|llll}
		\hline
		Number & Outlier & & & &\\ 
		of Years & Contamination & Ran-Sys & Ran-Sys-Ran & Sys-Ran & Sys-Ran-Sys\\ 
		\hline
		 & 0\% & \textbf{0.059\% (97\%)} & 0.065\% (3\%) & 0.065\% (0\%) & 0.065\% (0\%) \\ 
		 & 1\% & \textbf{0.055\% (97\%)} & 0.063\% (3\%) & 0.063\% (0\%) & 0.063\% (0\%) \\ 
		20 & 2\% & \textbf{0.052\% (97\%)} & 0.060\% (0\%) & 0.060\% (3\%) & 0.060\% (0\%) \\ 
		 & 5\% & \textbf{0.043\% (100\%)} & 0.054\% (0\%) & 0.054\% (0\%) & 0.054\% (0\%) \\ 
		 & 10\% & \textbf{0.032\% (100\%)} & 0.046\% (0\%) & 0.046\% (0\%) & 0.046\% (0\%) \\ 
		\hline
		 & 0\% & \textbf{0.054\% (97\%)} & 0.064\% (3\%) & 0.064\% (0\%) & 0.064\% (0\%) \\ 
		 & 1\% & \textbf{0.051\% (97\%)} & 0.061\% (3\%) & 0.061\% (0\%) & 0.061\% (0\%) \\ 
		40 & 2\% & \textbf{0.048\% (100\%)} & 0.059\% (0\%) & 0.059\% (0\%) & 0.059\% (0\%) \\ 
		 & 5\% & \textbf{0.039\% (100\%)} & 0.053\% (0\%) & 0.053\% (0\%) & 0.053\% (0\%) \\ 
		 & 10\% & \textbf{0.030\% (100\%)} & 0.046\% (0\%) & 0.045\% (0\%) & 0.045\% (0\%) \\ 
		\hline
		 & 0\% & \textbf{0.046\% (100\%)} & 0.061\% (0\%) & 0.061\% (0\%) & 0.061\% (0\%) \\ 
		 & 1\% & \textbf{0.043\% (100\%)} & 0.059\% (0\%) & 0.059\% (0\%) & 0.059\% (0\%) \\ 
		80 & 2\% & \textbf{0.040\% (100\%)} & 0.057\% (0\%) & 0.057\% (0\%) & 0.057\% (0\%) \\ 
		 & 5\% & \textbf{0.034\% (100\%)} & 0.051\% (0\%) & 0.051\% (0\%) & 0.051\% (0\%) \\ 
		 & 10\% & \textbf{0.025\% (100\%)} & 0.044\% (0\%) & 0.043\% (0\%) & 0.043\% (0\%) \\ 
		\hline
	\end{tabular}
	\caption{Fitted FPR averaged over all station and pressure level combinations.  Numbers in parentheses indicate the percent of station and pressure level combinations where the given sequencing obtained the lowest fitted FPR. Bolded numbers are the lowest within each row.}
	\label{tab:fitFPR}
\end{table}
\end{landscape}

\begin{landscape}
\begin{table}[ht]
	\centering
	\begin{tabular}{cc|llll}
		\hline
		Number & Outlier & & & &\\ 
		of Years & Contamination & Ran-Sys & Ran-Sys-Ran & Sys-Ran & Sys-Ran-Sys\\ 
		\hline
		 & 0\% & 61.4\% (0\%) & 61.4\% (0\%) & 61.3\% (0\%) & \textbf{61.8\% (100\%)} \\ 
  		 & 1\% & 65.2\% (0\%) & 65.2\% (0\%) & 65.1\% (0\%) & \textbf{65.6\% (100\%)} \\ 
  		20 & 2\% & 68.8\% (0\%) & 68.8\% (0\%) & 68.7\% (0\%) & \textbf{69.2\% (100\%)} \\ 
  		 & 5\% & 78.4\% (0\%) & 78.4\% (0\%) & 78.3\% (0\%) & \textbf{78.6\% (100\%)} \\ 
  		 & 10\% & 89.3\% (0\%) & 89.3\% (0\%) & 89.2\% (0\%) & \textbf{89.4\% (100\%)} \\ 
  		\hline
  		 & 0\% & 73.3\% (0\%) & 73.3\% (0\%) & 73.2\% (0\%) & \textbf{73.6\% (100\%)} \\ 
  		 & 1\% & 77.8\% (0\%) & 77.8\% (0\%) & 77.7\% (0\%) & \textbf{78.0\% (100\%)} \\ 
  		40 & 2\% & 81.7\% (0\%) & 81.7\% (0\%) & 81.6\% (0\%) & \textbf{81.9\% (100\%)} \\ 
  		 & 5\% & 90.2\% (0\%) & 90.2\% (0\%) & 90.2\% (0\%) & \textbf{90.4\% (100\%)} \\ 
  		 & 10\% & 97.0\% (0\%) & 97.0\% (0\%) & 97.0\% (0\%) & \textbf{97.0\% (100\%)} \\ 
  		\hline
  		 & 0\% & 88.7\% (0\%) & 88.7\% (0\%) & 88.7\% (0\%) & \textbf{88.9\% (100\%)} \\ 
  		 & 1\% & 92.1\% (0\%) & 92.1\% (0\%) & 92.1\% (0\%) & \textbf{92.2\% (100\%)} \\ 
  		80 & 2\% & 94.6\% (0\%) & 94.6\% (0\%) & 94.6\% (0\%) & \textbf{94.7\% (100\%)} \\ 
  		 & 5\% & 98.3\% (0\%) & 98.3\% (0\%) & 98.3\% (0\%) & \textbf{98.4\% (100\%)} \\ 
  		 & 10\% & 99.8\% (0\%) & 99.8\% (0\%) & 99.8\% (0\%) & \textbf{99.8\% (100\%)} \\ 
  		\hline
	\end{tabular}
	\caption{Fitted efficiency averaged over all station and pressure level combinations.  Numbers in parentheses indicate the percent of station and pressure level combinations where the given sequencing obtained the highest fitted efficiency. Bolded numbers are the highest within each row.}
	\label{tab:fitEff}
\end{table}
\end{landscape}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%FIGURES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\begin{figure}[h!]
	\centering
	\begin{tabular}{cc}
		\includegraphics[width=.5\textwidth]{70219_Data_Unhomogenized_no_vlines} &
		\includegraphics[width=.5\textwidth]{70219_Data_Unhomogenized_zoomed_no_vlines}
	\end{tabular}
	\caption{Temperature for Station 70219 plotted over time.  The second image is the same as the first but zoomed in to the last ten years to show more detail.}
	\label{fig:BasicTS}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=.9\textwidth]{35121_time_series.png}\\
	\includegraphics[width=.45\textwidth]{35121_simulated_1.png}
	\includegraphics[width=.45\textwidth]{35121_contaminated_1.png}\\
	\includegraphics[width=.45\textwidth]{35121_simulated_2.png}
	\includegraphics[width=.45\textwidth]{35121_contaminated_2.png}\\
	\includegraphics[width=.45\textwidth]{35121_simulated_3.png}
	\includegraphics[width=.45\textwidth]{35121_contaminated_3.png}\\
	\caption{Time series plots of radiosonde temperature data from station 35121.  The top plot shows the observed time series, and the following 3 pairs show three realizations of simulated datasets.  The plots on the left show the simulated data prior to contamination, and the right plots show the data after contamination with random and systematic errors.}
	\label{fig:simExample}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{homogenization_efficiency_boxplots}
	\caption{Boxplot of efficiency scores for the various homogenization algorithms.  Note that this graph is constrained to the efficiency range of $(-3,1)$ in order to show more detail.  The SNHT and the robust SNHT perform substantially  better than their alternatives.}
	\label{fig:homEfficiency}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{Efficiency_Model_Plot_BW}
	\caption{This graph depicts the estimated probability from the efficiency logistic regression model.  The middle of each error bar is the estimated probability of an efficiency greater than 0 averaged over all station and pressure level combinations.  The maximum (minimum) of the error bar is the highest (lowest) efficiency obtained across all station and pressure level combinations.  For clarity not all homogenization algorithms are plotted, but the ones left out performed worse than those shown here.}
	\label{fig:homFitEff}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{TPR_Order_Plot_BW}
	\caption{This graph depicts the estimated TPR from the logistic regression model.  The middle of each error bar is the estimated TPR averaged over all station and pressure level combinations.  The maximum (minimum) of the error bar is the highest (lowest) TPR obtained across all station and pressure level combinations.}
	\label{fig:fitTPR}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{FPR_Order_Plot_BW}
	\caption{This graph depicts the estimated FPR from the logistic regression model.  The middle of each error bar is the estimated FPR averaged over all station and pressure level combinations.  The maximum (minimum) of the error bar is the highest (lowest) FPR obtained across all station and pressure level combinations.}
	\label{fig:fitFPR}
\end{figure}


\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{Efficiency_Order_Plot_BW}
	\caption{This graph depicts the estimated efficiency from the logistic regression model.  The middle of each error bar is the estimated efficiency averaged over all station and pressure level combinations.  The maximum (minimum) of the error bar is the highest (lowest) efficiency obtained across all station and pressure level combinations.}
	\label{fig:fitEffOrd}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=.9\textwidth]{"70219_Data_Unhomogenized_zoomed"}
	\includegraphics[width=.9\textwidth]{"70219_Data_Homogenized_zoomed"}
	\includegraphics[width=.9\textwidth]{"70219_Data_Homogenized"}	
	\caption{Time series plot of the radiosonde temperature data at station 70219 (Bethel, Alaska, USA).  The top plot shows the data prior to the quality control algorithm, and the other two show the data after.  Dashed lines indicate detected change points, numbers indicate the magnitude of the corresponding change point, and dots indicate detected random errors.}
	\label{fig:caseStudy}
\end{figure}

%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%
